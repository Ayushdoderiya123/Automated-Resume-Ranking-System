{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from PyPDF2 import PdfReader\n",
    "import re \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=\"\"\"**Job Title**: Data Analyst\n",
    "\n",
    "**Company Overview**: \n",
    "XYZ Tech Solutions is a leading provider of innovative data solutions for businesses across various industries. Our mission is to empower organizations to harness the power of data to drive growth and efficiency.\n",
    "\n",
    "**Job Summary**: \n",
    "We are seeking a Data Analyst who will play a critical role in analyzing complex data sets to provide actionable insights and support data-driven decision-making processes.\n",
    "\n",
    "**Essential Job Functions**:\n",
    "- Analyze and interpret data from various sources to identify trends and patterns.\n",
    "- Develop and maintain dashboards and reports to visualize data insights.\n",
    "- Collaborate with cross-functional teams to understand data needs and provide solutions.\n",
    "- Present findings to stakeholders and recommend data-driven strategies.\n",
    "- Conduct data quality assessments and recommend improvements.\n",
    "\n",
    "**Qualifications/Requirements**:\n",
    "- Bachelor’s degree in Data Science, Statistics, Computer Science, or a related field.\n",
    "- 1-3 years of experience in a data analysis role or similar position.\n",
    "- Proficiency in SQL, Python, and data visualization tools (e.g., Tableau, Power BI).\n",
    "- Strong analytical skills and attention to detail.\n",
    "- Excellent communication skills, with the ability to explain complex data concepts to non-technical stakeholders.\n",
    "\n",
    "**Preferred Qualifications**:\n",
    "- Experience with machine learning techniques.\n",
    "- Familiarity with big data technologies (e.g., Hadoop, Spark).\n",
    "\n",
    "**Work Environment**: \n",
    "We promote a collaborative and inclusive work culture that values diverse perspectives and ideas.\n",
    "\n",
    "**Compensation and Benefits**: \n",
    "We offer a competitive salary, performance bonuses, and a comprehensive benefits package.\n",
    "\n",
    "**Equal Opportunity Statement**:\n",
    "XYZ Tech Solutions is an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file):\n",
    "    pdf = PdfReader(file)\n",
    "    text = \" \"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "    return text    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume =extract_text_from_pdf(\"AYUSH SHARMA RESUME.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' AYUSH SHARMA\\nSUMMARY\\nFinal-year engineering student specializing in Artificial Intelligence and Machine Learning. Proficient\\nin machine learning algorithms, data analysis, and model development. Eager to apply technical\\nskills and knowledge in a data science role to solve complex business problems. Strong analytical\\nmindset with a passion for data-driven decision-making. Seeking opportunities to contribute and\\ngrow as a fresher in the field of data science.\\nSKILLS\\nImplemented a spam SMS classifier using the Naive Bayes algorithm and TF-IDF Vectorizer,\\nleveraging NLTK for preprocessing tasks such as WordTokenizer and stopword removal.\\nEmployed TF-IDF Vectorizer to transform text data into meaningful features, improving the\\nmodel’s ability to distinguish between spam and non-spam messagesC++  ||  Python  ||  Machine Learning  ||  MySQL  ||  Power BI  ||  Data Analytics  ||  OOPS\\nSpam SMS Classifier\\nBuilt a machine learning model to predict laptop prices based on specifications like RAM,\\nstorage type and capacity, brand, processor, and GPU presence.\\nApplied Random Forest regression algorithms to accurately estimate prices, optimizing the\\nmodel through data preprocessing and feature engineering.Laptop Price Predictor\\nBuilt a deep learning project to classify whether the potato plant is healthy or suffering from\\nlate blight or early blight disease using image data.\\nUtilized convolutional neural networks (CNN) for image processing and disease detection,\\nenabling accurate classification of potato plant diseases • B-16, Staff Quarters , PCMS Campus, Bhanpur, Bhopal • 9685690893 • ayushdoderiya@gmail.com\\n• linkedin.com/in/ayush-sharma-b5b621258 • https://github.com/Ayushdoderiya123 \\nPROJECTS\\nPotato Plant Disease Classifier\\nMovie Recommendation System\\nBuilt a content-based movie recommender system, utilizing features like genre, plot, and\\nactors to suggest movies similar to those a user has liked.\\nApplied natural language processing (NLP) techniques to analyze movie descriptions and\\ncompute similarity scores for personalized recommendations.\\nLeveraged cosine similarity and TF-IDF Vectorizer to compare movies based on content\\nattributes, improving the relevance and accuracy of recommendations.\\nHR Data Analysis Project \\nConducted a detailed analysis of employee preferences for remote work vs. office work,\\nuncovering trends in productivity, engagement, and satisfaction.\\nDeveloped interactive dashboards using Power BI, presenting insights into employee\\nbehavior and key factors affecting work preference.\\nEnabled HR teams to make data-driven decisions by delivering actionable insights that\\ninformed policies on workplace flexibility and improved employee retention.EDUCATION\\nB.Tech in Artificial Intelligence and Machine Learning (Pursuing)\\nSagar Institute of Research and Technology , Bhopal\\nCGPA: 7.80/10 \\nClass 12th CBSE Board\\nSt. George Sr. Sec. School\\nPercent : 79.6 % Aug 2021 - May 2025\\n March 2020 - March 2021\\nClass 10th CBSE Board\\nSt. George Sr. Sec. School\\nPercent : 83.6 % March 2018 - March 2019\\nADDITIONAL INFORMATION\\nCertifications :- Core Python from Sharma Computer Academy , Machine Learning from Great\\nLearning , Data Analytics from Geeks of Gurukul.\\nLanguage Known :- English , Hindi\\nHobbies :- Playing Badminton.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()  # Get first letter of POS tag\n",
    "    tag_dict = {'J': wordnet.ADJ, 'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4048\\2674308263.py:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  schar=\"!@#$%^&*/?\\|':.,;[]-+\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schar=\"!@#$%^&*/?\\|':.,;[]-+\"\n",
    "# Preprocessing function\n",
    "def preprocess_txt(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [\n",
    "        lemmatizer.lemmatize(word.lower(), get_wordnet_pos(word))\n",
    "        for word in words\n",
    "        if word.lower() not in stop_words and word not in schar\n",
    "    ]\n",
    "    return ' '.join(filtered_words) \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = preprocess_txt(resume)\n",
    "job_description=preprocess_txt(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ayush sharma summary final-year engineering student specialize artificial intelligence machine learn proficient machine learn algorithm data analysis model development eager apply technical skill knowledge data science role solve complex business problem strong analytical mindset passion data-driven decision-making seek opportunity contribute grow fresher field data science skill implement spam sm classifier use naive bayes algorithm tf-idf vectorizer leverage nltk preprocessing task wordtokenizer stopword removal employ tf-idf vectorizer transform text data meaningful feature improve model ’ ability distinguish spam non-spam messagesc++ || python || machine learn || mysql || power bi || data analytics || oops spam sm classifier build machine learn model predict laptop price base specification like ram storage type capacity brand processor gpu presence applied random forest regression algorithm accurately estimate price optimize model data preprocessing feature engineering.laptop price predictor build deep learn project classify whether potato plant healthy suffer late blight early blight disease use image data utilize convolutional neural network ( cnn ) image processing disease detection enable accurate classification potato plant disease • b-16 staff quarter pcms campus bhanpur bhopal • 9685690893 • ayushdoderiya gmail.com • linkedin.com/in/ayush-sharma-b5b621258 • http //github.com/ayushdoderiya123 project potato plant disease classifier movie recommendation system build content-based movie recommender system utilize feature like genre plot actor suggest movie similar user like applied natural language processing ( nlp ) technique analyze movie description compute similarity score personalize recommendation leveraged cosine similarity tf-idf vectorizer compare movie base content attribute improve relevance accuracy recommendation hr data analysis project conduct detailed analysis employee preference remote work vs. office work uncover trend productivity engagement satisfaction develop interactive dashboard use power bi present insight employee behavior key factor affect work preference enable hr team make data-driven decision deliver actionable insight inform policy workplace flexibility improve employee retention.education b.tech artificial intelligence machine learn ( pursue ) sagar institute research technology bhopal cgpa 7.80/10 class 12th cbse board st. george sr. sec school percent 79.6 aug 2021 may 2025 march 2020 march 2021 class 10th cbse board st. george sr. sec school percent 83.6 march 2018 march 2019 additional information certification core python sharma computer academy machine learn great learn data analytics geek gurukul language know english hindi hobby play badminton'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resumes(job_description, resumes):\n",
    "    # Preprocess job description and resumes\n",
    "    documents = [preprocess_txt(job_description)] + [preprocess_txt(resume) for resume in resumes]\n",
    "\n",
    "    # Compute TF-IDF vectors for all documents\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    job_vector = vectors[0]  # First vector is the job description\n",
    "    similarity_scores = cosine_similarity(job_vector, vectors[1:])  # Compare with resumes\n",
    "\n",
    "    # Create a list of tuples (resume_index, similarity_score)\n",
    "    ranked_resumes = sorted(enumerate(similarity_scores.flatten()), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.28410155647262864)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_resumes(job_description,[resume])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
